# Cloud Storage and Malware Scanning

This document provides comprehensive guidance on configuring cloud storage (S3/R2) and malware scanning for secure file uploads in the Electrical Supplier B2B website.

## Table of Contents

1. [Overview](#overview)
2. [Storage Providers](#storage-providers)
3. [Malware Scanning](#malware-scanning)
4. [Configuration Guide](#configuration-guide)
5. [API Reference](#api-reference)
6. [Deployment Best Practices](#deployment-best-practices)
7. [Troubleshooting](#troubleshooting)

---

## Overview

The file upload system supports three storage backends and three malware scanning providers, providing flexibility for different deployment scenarios:

**Storage Options:**

- **Local** - Files stored on server filesystem (development/small deployments)
- **AWS S3** - Scalable cloud storage with global reach
- **Cloudflare R2** - S3-compatible storage with typically lower/zero egress fees (verify current pricing)

**Security Features:**

- **File type validation** - Magic byte verification (not just extension checking)
- **Malware scanning** - Optional integration with VirusTotal or ClamAV
- **Size limits** - Configurable maximum file sizes
- **Path traversal protection** - Sanitized filenames and security checks
- **Rate limiting** - Upload endpoint protection

---

## Storage Providers

### Local Storage (Default)

Files are stored in the local filesystem under the `UPLOAD_DIR` directory.

**Pros:**

- Simple setup - no external dependencies
- Low direct cost (uses your server storage)
- Fast for small deployments
- Full control over files

**Cons:**

- Not scalable for high traffic
- Requires disk space on server
- No CDN integration
- Files can be lost if the server fails (unless backed up)

**Configuration:**

```env
STORAGE_PROVIDER=local
UPLOAD_DIR=./uploads
```

**Best for:** Development, testing, small deployments with single server

---

### AWS S3

Industry-standard cloud object storage with global infrastructure.

**Pros:**

- Highly scalable and reliable
- Global CDN integration (CloudFront)
- Versioning and lifecycle policies
- Fine-grained access control (IAM)
- Server-side encryption

**Cons:**

- Egress bandwidth costs
- Requires AWS account setup
- Slightly higher latency vs local

**Configuration:**

```env
STORAGE_PROVIDER=s3
S3_REGION=us-east-1
S3_BUCKET=your-bucket-name
S3_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID
S3_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY
S3_PUBLIC_URL=https://cdn.yoursite.com
S3_PUBLIC_BUCKET=true
```

**Setup Steps:**

1. **Create S3 Bucket**

   ```bash
   aws s3 mb s3://your-bucket-name --region us-east-1
   ```

2. **Configure Bucket Policy** (for public read access)

   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Sid": "PublicReadGetObject",
         "Effect": "Allow",
         "Principal": "*",
         "Action": "s3:GetObject",
         "Resource": "arn:aws:s3:::your-bucket-name/*"
       }
     ]
   }
   ```

3. **Create IAM User with Permissions**

   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Action": [
           "s3:PutObject",
           "s3:GetObject",
           "s3:DeleteObject",
           "s3:ListBucket"
         ],
         "Resource": [
           "arn:aws:s3:::your-bucket-name/*",
           "arn:aws:s3:::your-bucket-name"
         ]
       }
     ]
   }
   ```

4. **Optional: Configure CloudFront CDN**
   - Create CloudFront distribution pointing to S3 bucket
   - Set `S3_PUBLIC_URL` to CloudFront URL

**Best for:** Production deployments, high traffic, global user base

---

### Cloudflare R2

S3-compatible storage with zero egress fees.

**Pros:**

- S3-compatible API (easy migration)
- No egress bandwidth fees for many R2 plans (verify current pricing)
- Cloudflare CDN integration
- Often lower cost than S3 for similar workloads (verify current pricing)
- DDoS protection included (as part of Cloudflare platform features)

**Cons:**

- Newer service (less mature than S3)
- Requires Cloudflare account
- Smaller ecosystem than AWS

**Configuration:**

```env
STORAGE_PROVIDER=r2
S3_REGION=auto
S3_BUCKET=your-bucket-name
S3_ACCESS_KEY_ID=your-r2-access-key-id
S3_SECRET_ACCESS_KEY=your-r2-secret-access-key
S3_ENDPOINT=https://1234567890abcdef.r2.cloudflarestorage.com
S3_PUBLIC_URL=https://uploads.yoursite.com
S3_PUBLIC_BUCKET=true
```

**Setup Steps:**

1. **Create R2 Bucket** (in Cloudflare dashboard)
   - Navigate to R2 → Create bucket
   - Choose a unique bucket name

2. **Create API Token**
   - R2 → Manage R2 API Tokens → Create API Token
   - Permissions: Object Read & Write
   - Copy Access Key ID and Secret Access Key

3. **Configure Public Access** (optional)
   - R2 bucket settings → Public access
   - Enable "Allow public access"
   - Or configure custom domain for CDN

4. **Set Custom Domain** (recommended)
   - R2 bucket → Settings → Custom domains
   - Add domain (e.g., `uploads.yoursite.com`)
   - Set `S3_PUBLIC_URL=https://uploads.yoursite.com`

**Best for:** Production deployments with cost-consciousness, Cloudflare users

---

## Malware Scanning

### No Scanning (Default)

Files are not scanned for malware - only file type validation is performed.

**Configuration:**

```env
MALWARE_SCAN_PROVIDER=none
```

**Best for:** Development, trusted environments, low-risk file types

---

### VirusTotal

Cloud-based malware scanning with 70+ antivirus engines.

**Pros:**

- Comprehensive scanning (70+ engines)
- Cloud-based (no server resources)
- Hash-based caching (fast results for known files)
- Detailed threat reports

**Cons:**

- Requires API key (limited free tier)
- 32MB file size limit (public API)
- Scan time: 5-30 seconds (varies)
- Files may be shared with the provider depending on plan/settings; verify current VirusTotal terms

**Configuration:**

```env
MALWARE_SCAN_PROVIDER=virustotal
VIRUSTOTAL_API_KEY=your-api-key-here
```

**Setup Steps:**

1. **Get API Key**
   - Sign up at https://www.virustotal.com/
   - Navigate to https://www.virustotal.com/gui/my-apikey
   - Copy your API key

2. **API Limits**
   - **Free tier:** 500 requests/day, 4 requests/minute
   - **Premium:** Higher limits + private scanning
   - **File size limit:** 32MB (public API), 650MB (premium)

**Behavior:**

- Files are submitted to VirusTotal for scanning
- First checks if file hash exists in database (instant result)
- If not found, uploads file and polls for results (5-30 seconds)
- If threat detected, upload is rejected
- Logs all scan results for audit trail

**Best for:** Production environments where comprehensive scanning is critical

---

### ClamAV

Open-source antivirus engine running on your infrastructure.

**Pros:**

- Open source and free
- Self-hosted (data privacy)
- Fast scanning for many files (depends on file size and host resources)
- No file size limits
- No API rate limits

**Cons:**

- Requires infrastructure setup
- Single engine (less comprehensive than VirusTotal)
- Requires regular signature updates
- CPU/memory overhead

**Configuration:**

```env
MALWARE_SCAN_PROVIDER=clamav
CLAMAV_HOST=localhost
CLAMAV_PORT=8080
```

**Setup Steps:**

1. **Run ClamAV with Docker**

   ```bash
   docker run -d \
     --name clamav \
     -p 8080:8080 \
     mkodockx/docker-clamav:alpine
   ```

2. **Or Install Natively**

   ```bash
   # Ubuntu/Debian
   sudo apt-get install clamav clamav-daemon
   sudo systemctl start clamav-daemon

   # Update virus definitions
   sudo freshclam
   ```

3. **Configure REST API** (for HTTP scanning)
   - Use `clamav-rest` or similar HTTP wrapper
   - Default port: 8080

**Best for:** Privacy-conscious deployments, high-volume uploads, self-hosted infrastructure

---

## Configuration Guide

### Environment Variables

#### Core Upload Settings

```env
# File Upload
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=5242880              # 5MB in bytes
MAX_FILES_PER_UPLOAD=10
ALLOWED_IMAGE_TYPES=image/jpeg,image/png,image/webp
ALLOWED_DOC_TYPES=application/pdf
```

#### Storage Provider

```env
# Storage Provider (local, s3, or r2)
STORAGE_PROVIDER=local

# AWS S3 / Cloudflare R2 Configuration
S3_REGION=us-east-1                # or 'auto' for R2
S3_BUCKET=your-bucket-name
S3_ACCESS_KEY_ID=your-access-key
S3_SECRET_ACCESS_KEY=your-secret-key
S3_ENDPOINT=                       # Required for R2, optional for S3
S3_PUBLIC_URL=                     # CDN URL (optional)
S3_PUBLIC_BUCKET=true              # Make files publicly readable
```

#### Malware Scanning

```env
# Malware Scanning Provider (none, virustotal, or clamav)
MALWARE_SCAN_PROVIDER=none

# VirusTotal
VIRUSTOTAL_API_KEY=your-vt-api-key

# ClamAV
CLAMAV_HOST=localhost
CLAMAV_PORT=8080
```

### Production Recommendations

**Small Deployment (< 1000 files/day):**

```env
STORAGE_PROVIDER=local
MALWARE_SCAN_PROVIDER=clamav
```

**Medium Deployment (1K-10K files/day):**

```env
STORAGE_PROVIDER=s3  # or r2
MALWARE_SCAN_PROVIDER=clamav
```

**Large Deployment (> 10K files/day):**

```env
STORAGE_PROVIDER=r2  # Zero egress costs
MALWARE_SCAN_PROVIDER=clamav  # Self-hosted for performance
```

**High Security:**

```env
STORAGE_PROVIDER=s3  # or r2
MALWARE_SCAN_PROVIDER=virustotal  # 70+ engines
MAX_FILE_SIZE=2097152  # 2MB limit
```

---

## API Reference

### Upload Single File

**Endpoint:** `POST /api/v1/uploads/single`

**Authentication:** Required (JWT token)

**Request:**

```bash
curl -X POST http://localhost:5000/api/v1/uploads/single \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "file=@image.jpg"
```

**Response (Success):**

```json
{
  "success": true,
  "data": {
    "filename": "file-1234567890-123456789.jpg",
    "originalname": "image.jpg",
    "mimetype": "image/jpeg",
    "size": 152304,
    "url": "https://cdn.yoursite.com/images/file-1234567890-123456789.jpg",
    "key": "images/file-1234567890-123456789.jpg"
  }
}
```

**Response (Malware Detected):**

```json
{
  "success": false,
  "message": "File failed security scan: potential threat detected"
}
```

---

### Upload Multiple Files

**Endpoint:** `POST /api/v1/uploads/multiple`

**Authentication:** Required (JWT token)

**Request:**

```bash
curl -X POST http://localhost:5000/api/v1/uploads/multiple \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "files=@image1.jpg" \
  -F "files=@image2.png" \
  -F "files=@document.pdf"
```

**Response:**

```json
{
  "success": true,
  "data": [
    {
      "filename": "file-1234567890-123456789.jpg",
      "originalname": "image1.jpg",
      "mimetype": "image/jpeg",
      "size": 152304,
      "url": "https://cdn.yoursite.com/images/file-1234567890-123456789.jpg",
      "key": "images/file-1234567890-123456789.jpg"
    },
    {
      "filename": "file-1234567890-987654321.png",
      "originalname": "image2.png",
      "mimetype": "image/png",
      "size": 98745,
      "url": "https://cdn.yoursite.com/images/file-1234567890-987654321.png",
      "key": "images/file-1234567890-987654321.png"
    }
  ]
}
```

---

### Delete File

**Endpoint:** `DELETE /api/v1/uploads/:type/:filename`

**Authentication:** Required (JWT token)

**Parameters:**

- `type` - File type folder (`images` or `documents`)
- `filename` - Name of file to delete

**Request:**

```bash
curl -X DELETE http://localhost:5000/api/v1/uploads/images/file-1234567890-123456789.jpg \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**Response:**

```json
{
  "success": true,
  "message": "File deleted successfully"
}
```

---

## Deployment Best Practices

### Security

1. **Always enable malware scanning in production**

   ```env
   MALWARE_SCAN_PROVIDER=virustotal  # or clamav
   ```

2. **Use restrictive file type allowlists**

   ```env
   ALLOWED_IMAGE_TYPES=image/jpeg,image/png,image/webp
   ALLOWED_DOC_TYPES=application/pdf
   ```

3. **Set conservative file size limits**

   ```env
   MAX_FILE_SIZE=5242880  # 5MB
   MAX_FILES_PER_UPLOAD=10
   ```

4. **Enable HTTPS for all uploads**
   - Use Cloudflare, AWS CloudFront, or nginx with Let's Encrypt
   - Set `CORS_ORIGIN` to your frontend domain

5. **Implement upload rate limiting**
   - Already configured in `rateLimit.middleware.ts`
   - Adjust limits based on your needs

### Performance

1. **Use CDN for file delivery**

   ```env
   S3_PUBLIC_URL=https://cdn.yoursite.com
   ```

2. **Choose storage provider by usage**
   - **Low traffic:** Local storage
   - **Medium traffic:** AWS S3 + CloudFront
   - **High traffic:** Cloudflare R2 (zero egress fees)

3. **Optimize malware scanning**
   - **ClamAV:** Fast (< 1s), use for high volume
   - **VirusTotal:** Thorough, use for critical security

4. **Enable storage lifecycle policies**
   - S3/R2: Auto-delete old files
   - Local: Set up cron job for cleanup

### Monitoring

1. **Track upload metrics**
   - File size distribution
   - Malware detection rate
   - Storage costs
   - Failed uploads

2. **Set up alerts**
   - Malware detected
   - Storage quota approaching limit
   - High error rate
   - Slow upload times

3. **Log security events**
   - All malware detections are logged via `logger.security()`
   - Monitor logs for patterns

### Cost Optimization

**AWS S3:**

- Enable Intelligent-Tiering for automatic cost optimization
- Set lifecycle policy to delete old files
- Use S3 Transfer Acceleration for global uploads
- **Estimated cost:** $0.023/GB storage + $0.09/GB egress

**Cloudflare R2:**

- Zero egress bandwidth charges
- Lower storage costs than S3
- **Estimated cost:** $0.015/GB storage + $0 egress

**Cost Comparison Example (1TB storage, 10TB egress/month):**

- **Local:** $0 (server disk space)
- **AWS S3:** $23 storage + $900 egress = **$923/month**
- **Cloudflare R2:** $15 storage + $0 egress = **$15/month**

---

## Troubleshooting

### Issue: "S3 upload failed"

**Cause:** Invalid credentials or insufficient permissions

**Solution:**

1. Verify credentials in `.env`

   ```bash
   aws s3 ls s3://your-bucket-name --profile your-profile
   ```

2. Check IAM policy includes required permissions:
   - `s3:PutObject`
   - `s3:GetObject`
   - `s3:DeleteObject`

3. For R2, verify endpoint URL format:
   ```env
   S3_ENDPOINT=https://1234567890abcdef.r2.cloudflarestorage.com
   ```

---

### Issue: "VirusTotal scan timed out"

**Cause:** Scan took longer than expected (> 30 seconds)

**Solution:**

1. File is allowed to upload (safe default behavior)
2. Check VirusTotal API status: https://www.virustotal.com/gui/home
3. Consider reducing `MAX_FILE_SIZE` to speed up scans
4. Upgrade to VirusTotal Premium for faster scanning

---

### Issue: "ClamAV not configured, skipping scan"

**Cause:** `CLAMAV_HOST` or `CLAMAV_PORT` not set

**Solution:**

1. Set environment variables:

   ```env
   CLAMAV_HOST=localhost
   CLAMAV_PORT=8080
   ```

2. Verify ClamAV is running:

   ```bash
   docker ps | grep clamav
   # or
   systemctl status clamav-daemon
   ```

3. Test connection:
   ```bash
   curl http://localhost:8080/health
   ```

---

### Issue: "File type not allowed"

**Cause:** File's actual MIME type doesn't match allowed types

**Solution:**

1. System uses **magic byte validation** (not just file extension)
2. Check file's actual MIME type:

   ```bash
   file --mime-type yourfile.jpg
   ```

3. Add MIME type to allowlist if legitimate:
   ```env
   ALLOWED_IMAGE_TYPES=image/jpeg,image/png,image/webp,image/gif
   ```

---

### Issue: "Local storage running out of disk space"

**Solution:**

1. **Short-term:** Clean up old files manually

   ```bash
   find ./uploads -type f -mtime +30 -delete  # Delete files older than 30 days
   ```

2. **Long-term:** Migrate to S3/R2

   ```bash
   # Sync existing files to S3
   aws s3 sync ./uploads s3://your-bucket-name/

   # Update environment
   STORAGE_PROVIDER=s3
   ```

3. **Alternative:** Set up automated cleanup cron job

---

### Monitoring Commands

**Check disk usage:**

```bash
du -sh ./uploads
```

**Count files:**

```bash
find ./uploads -type f | wc -l
```

**List largest files:**

```bash
find ./uploads -type f -exec ls -lh {} \; | sort -k5 -hr | head -10
```

**Test upload:**

```bash
curl -X POST http://localhost:5000/api/v1/uploads/single \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@test.jpg" \
  -v
```

---

## Migration Guide

### Local → S3

1. **Set up S3 bucket** (see [AWS S3](#aws-s3) section)

2. **Sync existing files:**

   ```bash
   aws s3 sync ./uploads s3://your-bucket-name/ \
     --acl public-read
   ```

3. **Update environment:**

   ```env
   STORAGE_PROVIDER=s3
   S3_BUCKET=your-bucket-name
   S3_REGION=us-east-1
   S3_ACCESS_KEY_ID=...
   S3_SECRET_ACCESS_KEY=...
   ```

4. **Test uploads** to verify new files go to S3

5. **Clean up local files** after verification

### S3 → R2

1. **Create R2 bucket** (see [Cloudflare R2](#cloudflare-r2) section)

2. **Copy files from S3 to R2:**

   ```bash
   # Using rclone
   rclone copy s3:your-s3-bucket r2:your-r2-bucket
   ```

3. **Update environment:**

   ```env
   STORAGE_PROVIDER=r2
   S3_ENDPOINT=https://...r2.cloudflarestorage.com
   ```

4. **Test and verify**

---

## Additional Resources

- [AWS S3 Documentation](https://docs.aws.amazon.com/s3/)
- [Cloudflare R2 Documentation](https://developers.cloudflare.com/r2/)
- [VirusTotal API Documentation](https://developers.virustotal.com/reference)
- [ClamAV Documentation](https://docs.clamav.net/)
- [Multer Documentation](https://github.com/expressjs/multer)

---

**Version:** 1.0.0  
**Maintained By:** Electrical Supplier Development Team
